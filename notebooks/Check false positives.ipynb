{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded configurations from (in order) ['../src/../config/default.ini', '../src/../config/notebook.ini']\n",
      "Loaded configurations from (in order) ['../config/default.ini', '../config/stack_on_3class_768.ini']\n",
      "Couldn't import dot_parser, loading of dot files will not be possible.\n",
      "OpenCV 2 NOT AVAILABLE, using skimage/scipy.ndimage instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 2: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import params\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_folder = '../models/'\n",
    "\n",
    "model_filename = '1475597561_stack_on_3class_768/1475597561_stack_on_3class_768_best_epoch90.npz'\n",
    "model_path = os.path.join(model_folder, model_filename)\n",
    "\n",
    "params.params = params.Params(['../config/default.ini'] + \n",
    "                              ['../config/stack_on_3class_768.ini'])\n",
    "from params import params as P\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import resnet\n",
    "\n",
    "import patch_sampling\n",
    "from cparallel import ContinuousParallelBatchIterator\n",
    "\n",
    "input_var = T.tensor4('inputs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train samplers\n",
      "Loading validation samplers\n",
      "Loading samplers took 35.1025540829 seconds.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator, train_sampler, validation_sampler = (\n",
    "    \n",
    "    patch_sampling.prepare_custom_sampler(mini_subset=False, override_cache_size=3, return_samplers=True)\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 192, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "# DEFINE AND LOAD NETWORK\n",
    "\n",
    "input_var = T.tensor4('inputs')\n",
    "target_var = T.ivector('targets')\n",
    "\n",
    "net = resnet.ResNet_FullPre_Wide(input_var, 4, 2)\n",
    "all_layers = lasagne.layers.get_all_layers(net)\n",
    "net = all_layers[-3]\n",
    "net = resnet.ResNet_Stacked(net)\n",
    "\n",
    "with np.load(model_path) as f:\n",
    "    param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "\n",
    "lasagne.layers.set_all_param_values(net, param_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_fn = resnet.define_predict(net, input_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 36\n",
    "X = [batch_size]*10000\n",
    "\n",
    "batch_gen = ContinuousParallelBatchIterator(validation_generator, \n",
    "                                            ordered=False, batch_size=1, multiprocess=False, n_producers=2)\n",
    "batch_gen.append(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "all_targets = []\n",
    "all_filenames = []\n",
    "all_imgs = []\n",
    "\n",
    "all_pred = []\n",
    "all_binary_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:16<00:00,  7.53s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(tqdm(batch_gen(10))):\n",
    "    inputs, targets, filenames = batch\n",
    "    \n",
    "    pred_binary, pred = predict_fn(inputs)\n",
    "    \n",
    "    for x in range(len(inputs)):\n",
    "        all_inputs.append(inputs[x])\n",
    "        filename = filenames[x]\n",
    "        target = targets[x]\n",
    "        p = pred[x]\n",
    "        p_binary = pred_binary[x]\n",
    "        \n",
    "        #all_inputs.append(inputs[x].astype(np.float16))\n",
    "        all_targets.append(target)\n",
    "        all_filenames.append(filename)\n",
    "        all_pred.append(p)\n",
    "        all_binary_pred.append(p_binary)\n",
    "            \n",
    "    del inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "623\n",
      "60\n",
      "10\n",
      "73\n",
      "626\n",
      "61\n",
      "37\n",
      "22\n",
      "648\n"
     ]
    }
   ],
   "source": [
    "# Create examples of errors (save as images) for use in article\n",
    "import util\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "err_types = [(0,0),(0,1),(0,2),(1,0),(1,1),(1,2),(2,0),(2,1),(2,2)]\n",
    "\n",
    "t = np.array(all_targets)\n",
    "p = np.array(all_binary_pred)\n",
    "\n",
    "save_dir = '../figures/errors/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "for er1, er2 in err_types:\n",
    "    image_indices =  np.where((p == er1),1,0) * np.where((t == er2),1,0)\n",
    "    #print np.where(image_indices==1)\n",
    "    image_indices = np.where(image_indices==1)[0]\n",
    "    print len(image_indices)\n",
    "    for i, x in enumerate(image_indices):\n",
    "        if i > 12: \n",
    "            break\n",
    "        im = util.unzero_center(np.array([all_inputs[x]]), P.MEAN_PIXEL)[0]\n",
    "        plt.imsave(save_dir+'err_'+str(er1)+'_'+str(+er2)+'_num'+str(i)+'.jpg', im.transpose(1,2,0))\n",
    "    \n",
    "\n",
    "        \n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_loss = {}\n",
    "file_count = {}\n",
    "file_target = {}\n",
    "\n",
    "for filename, target, prediction, prediction_binary, loss in zip(all_filenames, all_targets, all_pred, all_binary_pred, all_loss):\n",
    "    \n",
    "    if filename not in file_loss:\n",
    "        file_loss[filename] = 0\n",
    "        file_count[filename] = 0\n",
    "        \n",
    "    file_loss[filename] += loss\n",
    "    file_count[filename] += 1\n",
    "    file_target[filename] = target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Average loss per file\n",
    "file_avg_loss = {f:file_loss[f]/file_count[f] for f in np.unique(filenames)}\n",
    "import operator\n",
    "file_loss_tups = file_avg_loss.iteritems()\n",
    "# Sort by loss\n",
    "file_loss_tups = list(reversed(sorted(file_loss_tups, key=operator.itemgetter(1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of wrong labels 945 out of 9000\n"
     ]
    }
   ],
   "source": [
    "import util\n",
    "misclassified = np.array(all_binary_pred) != np.array(all_targets)\n",
    "print \"Amount of wrong labels\", np.sum(misclassified), \"out of\", len(all_targets)\n",
    "#wrong_images = util.unzero_center(wrong_images, P.MEAN_PIXEL)\n",
    "#wrong_images = wrong_images.transpose(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sampler_of_filename = {}\n",
    "\n",
    "all_samplers = []\n",
    "for x in validation_sampler.per_label_sampler_list.values():\n",
    "    print len(x)\n",
    "    all_samplers += x\n",
    "\n",
    "    \n",
    "i = 0\n",
    "for sampler in all_samplers:\n",
    "    \n",
    "    i += 1\n",
    "    #print sampler.filename\n",
    "    sampler_of_filename[sampler.filename] = sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrong_images = []\n",
    "\n",
    "for (f, l) in tqdm(file_loss_tups[:18]):\n",
    "    im = sampler_of_filename[f].sample_full()\n",
    "    im = util.normalize_image(im)\n",
    "    wrong_images.append(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.hist(file_count.values(), 50)\n",
    "plt.title(\"Frequency of samples from images\")\n",
    "plt.show()\n",
    "\n",
    "print all_filenames[np.argmax(file_count.values())]\n",
    "print np.max(file_count.values())\n",
    "\n",
    "plt.hist(np.array(all_loss)[misclassified], 10)\n",
    "plt.title(\"Loss of misclassified images frequencies\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions that are most wrong\n",
    "(Number in the title of the images is the loss of that prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "from dataset import label_name\n",
    "\n",
    "\n",
    "#For N by N plots\n",
    "N = 2\n",
    "\n",
    "\n",
    "for plot_number in range(0, len(wrong_images), N**2):\n",
    "    \n",
    "    if plot_number//N**2 >= 2: #Lets not plot too many\n",
    "        break\n",
    "        \n",
    "    f, axarr = plt.subplots(N,N,figsize=(16,16))\n",
    "    \n",
    "    for i in range(min(N**2, len(wrong_images)-plot_number)):\n",
    "        \n",
    "        x = int(i%N)\n",
    "        y = int(i/N)\n",
    "        \n",
    "        i = plot_number+i\n",
    "        \n",
    "        im = wrong_images[i].transpose(1,2,0)\n",
    "        filename, loss = file_loss_tups[i]\n",
    "        target = file_target[filename]\n",
    "        \n",
    "        \n",
    "        axarr[y,x].imshow(im)\n",
    "        axarr[y,x].set_title(label_name(target) + \" \" + str(loss))\n",
    "        axarr[y,x].axis('off')\n",
    "        \n",
    "    plt.subplots_adjust(wspace = -0.2, hspace=0.12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import util\n",
    "from dataset import label_name\n",
    "cm = sklearn.metrics.confusion_matrix(all_targets, all_binary_pred)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "label_names = ['Benign', 'DCIS', 'IDC']\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(cm_normalized, interpolation='nearest')\n",
    "plt.xticks(np.arange(0,3), label_names)\n",
    "plt.yticks(np.arange(0,3), label_names)\n",
    "plt.tight_layout()\n",
    "plt.colorbar()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Benign    DCIS     IDC\n",
      "     Benign   0.878   0.088   0.034\n",
      "       DCIS   0.068   0.904   0.028\n",
      "        IDC   0.015   0.081   0.904\n"
     ]
    }
   ],
   "source": [
    "# From https://gist.github.com/zachguo/10296432\n",
    "def print_cm(cm, labels, hide_zeroes=False, hide_diagonal=False, hide_threshold=None):\n",
    "    \"\"\"pretty print for confusion matrixes\"\"\"\n",
    "    columnwidth = max([len(x) for x in labels]+[7]) # 7 is value length\n",
    "    empty_cell = \" \" * columnwidth\n",
    "    # Print header\n",
    "    print \"    \" + empty_cell,\n",
    "    for label in labels: \n",
    "        print \"%{0}s\".format(columnwidth) % label,\n",
    "    print\n",
    "    # Print rows\n",
    "    for i, label1 in enumerate(labels):\n",
    "        print \"    %{0}s\".format(columnwidth) % label1,\n",
    "        for j in range(len(labels)): \n",
    "            cell = \"%{0}.3f\".format(columnwidth) % cm[i, j]\n",
    "            if hide_zeroes:\n",
    "                cell = cell if float(cm[i, j]) != 0 else empty_cell\n",
    "            if hide_diagonal:\n",
    "                cell = cell if i != j else empty_cell\n",
    "            if hide_threshold:\n",
    "                cell = cell if cm[i, j] > hide_threshold else empty_cell\n",
    "            print cell,\n",
    "        print \n",
    "    \n",
    "print_cm(cm_normalized, label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
